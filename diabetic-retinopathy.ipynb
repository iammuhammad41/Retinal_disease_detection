{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4104,
          "databundleVersionId": 46661,
          "sourceType": "competition"
        },
        {
          "sourceId": 265751,
          "sourceType": "datasetVersion",
          "datasetId": 110097
        },
        {
          "sourceId": 2269470,
          "sourceType": "datasetVersion",
          "datasetId": 1366461
        }
      ],
      "dockerImageVersionId": 30163,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iammuhammad41/Retinal_disease_detection/blob/main/diabetic-retinopathy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:17.670882Z",
          "iopub.execute_input": "2024-09-03T03:24:17.671197Z",
          "iopub.status.idle": "2024-09-03T03:24:17.677520Z",
          "shell.execute_reply.started": "2024-09-03T03:24:17.671161Z",
          "shell.execute_reply": "2024-09-03T03:24:17.676758Z"
        },
        "trusted": true,
        "id": "5B5AqpxFC7Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.data import Dataset\n",
        "from skimage.io import imread\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import *\n",
        "from skimage.io import *\n",
        "from glob import glob\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Necessary modules have been imported\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:17.679062Z",
          "iopub.execute_input": "2024-09-03T03:24:17.679278Z",
          "iopub.status.idle": "2024-09-03T03:24:17.692488Z",
          "shell.execute_reply.started": "2024-09-03T03:24:17.679251Z",
          "shell.execute_reply": "2024-09-03T03:24:17.691717Z"
        },
        "trusted": true,
        "id": "ZjAJfRyiC7Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_image(filename, label):\n",
        "    image = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "def load_dataset(file_paths, labels, batch_size=32):\n",
        "    dataset = Dataset.from_tensor_slices((file_paths, labels))\n",
        "    dataset = dataset.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(buffer_size=len(file_paths)).batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:17.693586Z",
          "iopub.execute_input": "2024-09-03T03:24:17.693860Z",
          "iopub.status.idle": "2024-09-03T03:24:17.703975Z",
          "shell.execute_reply.started": "2024-09-03T03:24:17.693819Z",
          "shell.execute_reply": "2024-09-03T03:24:17.703273Z"
        },
        "trusted": true,
        "id": "AkNu-UqmC7Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing labels"
      ],
      "metadata": {
        "id": "hnU0wv-2C7Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o /content/input/diabetic-retinopathy-detection/trainLabels.csv.zip\n",
        "trainLabels = pd.read_csv(\"/content/trainLabels.csv\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:17.705050Z",
          "iopub.execute_input": "2024-09-03T03:24:17.705335Z",
          "iopub.status.idle": "2024-09-03T03:24:18.880264Z",
          "shell.execute_reply.started": "2024-09-03T03:24:17.705295Z",
          "shell.execute_reply": "2024-09-03T03:24:18.879162Z"
        },
        "trusted": true,
        "id": "7lxJ5lVLC7Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install p7zip-full -y\n",
        "!7z x /content/input/diabetic-retinopathy-detection/train.zip.001 \"-i!train/11*.jpeg\" -y\n",
        "# restrict extracted file to about 100 for the disk restriction\n",
        "!mkdir data\n",
        "!mv train data/train_11\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:18.883313Z",
          "iopub.execute_input": "2024-09-03T03:24:18.883963Z",
          "iopub.status.idle": "2024-09-03T03:24:35.391664Z",
          "shell.execute_reply.started": "2024-09-03T03:24:18.883914Z",
          "shell.execute_reply": "2024-09-03T03:24:35.390549Z"
        },
        "trusted": true,
        "id": "AhHeZg3-C7Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = glob(\"/content/data/train_11/*.jpeg\")\n",
        "\n",
        "file_basenames = [os.path.basename(f).replace(\".jpeg\", \"\") for f in file_paths]\n",
        "\n",
        "filtered_labels = trainLabels[trainLabels['image'].isin(file_basenames)]['level'].values\n",
        "\n",
        "print(f\"Number of image files: {len(file_paths)}\")\n",
        "print(f\"Number of filtered labels: {len(filtered_labels)}\")\n",
        "\n",
        "dataset = load_dataset(file_paths, filtered_labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:35.395425Z",
          "iopub.execute_input": "2024-09-03T03:24:35.395782Z",
          "iopub.status.idle": "2024-09-03T03:24:35.441104Z",
          "shell.execute_reply.started": "2024-09-03T03:24:35.395729Z",
          "shell.execute_reply": "2024-09-03T03:24:35.440427Z"
        },
        "trusted": true,
        "id": "F-z6rM8WC7Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for n in range(5):\n",
        "        ax = plt.subplot(1, 5, n + 1)\n",
        "        plt.imshow(image_batch[n])\n",
        "        plt.title(int(label_batch[n]))\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_images_by_label(dataset, num_classes=5):\n",
        "    images = [None] * num_classes\n",
        "    labels = [None] * num_classes\n",
        "    label_counts = {i: 0 for i in range(num_classes)}\n",
        "\n",
        "    for image_batch, label_batch in dataset:\n",
        "        for img, lbl in zip(image_batch, label_batch):\n",
        "            label = int(lbl)\n",
        "            if label_counts[label] == 0:\n",
        "                images[label] = img\n",
        "                labels[label] = lbl\n",
        "                label_counts[label] += 1\n",
        "            if sum(label_counts.values()) == num_classes:\n",
        "                return np.array(images), np.array(labels)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "image_batch, label_batch = get_images_by_label(dataset)\n",
        "\n",
        "\n",
        "sorted_indices = np.argsort(label_batch)\n",
        "image_batch = image_batch[sorted_indices]\n",
        "label_batch = label_batch[sorted_indices]\n",
        "\n",
        "\n",
        "show_batch(image_batch, label_batch)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:35.442806Z",
          "iopub.execute_input": "2024-09-03T03:24:35.443106Z",
          "iopub.status.idle": "2024-09-03T03:24:49.763900Z",
          "shell.execute_reply.started": "2024-09-03T03:24:35.443063Z",
          "shell.execute_reply": "2024-09-03T03:24:49.763169Z"
        },
        "trusted": true,
        "id": "2kdSRf3RC7Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering and Balancing Data\n",
        "base_image_dir = os.path.join('.', 'data/train_11')\n",
        "trainLabels['path'] = trainLabels['image'].map(lambda x: os.path.join(base_image_dir,'{}.jpeg'.format(x)))\n",
        "trainLabels['exists'] = trainLabels['path'].map(os.path.exists)\n",
        "df = trainLabels[trainLabels['exists']]\n",
        "df = df.drop(columns=['image', 'exists'])\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df['level'] = df['level'].astype(str)\n",
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:49.764982Z",
          "iopub.execute_input": "2024-09-03T03:24:49.765204Z",
          "iopub.status.idle": "2024-09-03T03:24:49.998487Z",
          "shell.execute_reply.started": "2024-09-03T03:24:49.765175Z",
          "shell.execute_reply": "2024-09-03T03:24:49.997764Z"
        },
        "trusted": true,
        "id": "Iw-QVkxaC7Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize distribution\n",
        "df['level'].hist(figsize=(10, 5))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:49.999581Z",
          "iopub.execute_input": "2024-09-03T03:24:49.999814Z",
          "iopub.status.idle": "2024-09-03T03:24:50.228017Z",
          "shell.execute_reply.started": "2024-09-03T03:24:49.999784Z",
          "shell.execute_reply": "2024-09-03T03:24:50.227363Z"
        },
        "trusted": true,
        "id": "GG3fcrmVC7Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input, Conv2D, multiply, Lambda, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "def create_deeper_attention_model(input_shape, num_classes):\n",
        "    in_lay = Input(input_shape)\n",
        "    base_pretrained_model = InceptionV3(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_pretrained_model.trainable = False\n",
        "    pt_depth = base_pretrained_model.output_shape[-1]\n",
        "    pt_features = base_pretrained_model(in_lay)\n",
        "\n",
        "    bn_features = BatchNormalization()(pt_features)\n",
        "\n",
        "\n",
        "    attn_layer = Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(Dropout(0.5)(bn_features))\n",
        "    attn_layer = Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(attn_layer)\n",
        "    attn_layer = Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', kernel_regularizer=l2(0.001))(attn_layer)\n",
        "    attn_layer = Conv2D(1, kernel_size=(1,1), padding='valid', activation='sigmoid')(attn_layer)\n",
        "\n",
        "    up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
        "    up_c2 = Conv2D(pt_depth, kernel_size=(1,1), padding='same', activation='linear', use_bias=False, weights=[up_c2_w])\n",
        "    up_c2.trainable = False\n",
        "    attn_layer = up_c2(attn_layer)\n",
        "\n",
        "    mask_features = multiply([attn_layer, bn_features])\n",
        "    gap_features = GlobalAveragePooling2D()(mask_features)\n",
        "    gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
        "\n",
        "    gap = Lambda(lambda x: x[0]/x[1], name='RescaleGAP')([gap_features, gap_mask])\n",
        "    gap_dr = Dropout(0.5)(gap)\n",
        "    dr_steps = Dropout(0.5)(Dense(256, activation='relu', kernel_regularizer=l2(0.001))(gap_dr))\n",
        "    out_layer = Dense(num_classes, activation='softmax')(dr_steps)\n",
        "\n",
        "    model = Model(inputs=[in_lay], outputs=[out_layer])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy','AUC'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "attention_model = create_deeper_attention_model((256, 256, 3), 5)\n",
        "attention_model.summary()\n",
        "\n",
        "\n",
        "plot_model(attention_model, show_shapes=True, show_layer_names=True, dpi=60, to_file='model_architecture.png')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:50.229246Z",
          "iopub.execute_input": "2024-09-03T03:24:50.229505Z",
          "iopub.status.idle": "2024-09-03T03:24:53.936349Z",
          "shell.execute_reply.started": "2024-09-03T03:24:50.229473Z",
          "shell.execute_reply": "2024-09-03T03:24:53.935063Z"
        },
        "trusted": true,
        "id": "P6Te6XfkC7Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# Initialize lists to store fold results\n",
        "all_train_accu = []\n",
        "all_val_accu = []\n",
        "all_train_loss = []\n",
        "all_val_loss = []\n",
        "all_train_auc = []\n",
        "all_val_auc = []\n",
        "all_history = {'categorical_accuracy': [], 'val_categorical_accuracy': [],\n",
        "               'loss': [], 'val_loss': [], 'auc': [], 'val_auc': []}\n",
        "\n",
        "# Balance data function\n",
        "def balance_data(class_size, df):\n",
        "    train_df = df.groupby(['level']).apply(lambda x: x.sample(class_size, replace=True)).reset_index(drop=True)\n",
        "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "    print('New Data Size:', train_df.shape[0], 'Old Size:', df.shape[0])\n",
        "    train_df['level'].hist(figsize=(10, 5))\n",
        "    return train_df\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize cumulative confusion matrix\n",
        "cumulative_cm = None\n",
        "\n",
        "# Iterate through each fold\n",
        "for fold_index, (train_index, val_index) in enumerate(skf.split(df, df['level'])):\n",
        "    print(f\"Training fold {fold_index + 1}/{n_splits}\")\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_df, val_df = df.iloc[train_index], df.iloc[val_index]\n",
        "\n",
        "    # Ensure balanced class distribution\n",
        "    max_class_size = train_df.pivot_table(index='level', aggfunc=len).max().max()\n",
        "    train_df = balance_data(max_class_size, train_df)\n",
        "\n",
        "    # ImageDataGenerator for training and validation\n",
        "    train_datagen = ImageDataGenerator(rescale=1.0/255, shear_range=0.2, horizontal_flip=True, zoom_range=0.2)\n",
        "    test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "    x_train = train_datagen.flow_from_dataframe(train_df, directory=\".\", x_col=\"path\", y_col=\"level\", target_size=(256, 256), batch_size=32, class_mode='categorical')\n",
        "    x_test = test_datagen.flow_from_dataframe(val_df, x_col=\"path\", y_col=\"level\", directory=\".\", target_size=(256, 256), batch_size=32, class_mode='categorical')\n",
        "\n",
        "    # Initialize cumulative confusion matrix\n",
        "    if cumulative_cm is None:\n",
        "        cumulative_cm = np.zeros((len(x_train.class_indices), len(x_train.class_indices)), dtype=int)\n",
        "\n",
        "    # Create and train the model\n",
        "    attention_model = create_deeper_attention_model((256, 256, 3), len(x_train.class_indices))\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    filepath = f\"dr-detector-fold{fold_index + 1}-{current_time}-{{epoch:02d}}-{{val_categorical_accuracy:.2f}}.hdf5\"\n",
        "\n",
        "    # Callbacks\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor=\"val_categorical_accuracy\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "    earlystop = EarlyStopping(monitor='val_categorical_accuracy', verbose=1, min_delta=0, patience=15, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.1, patience=7, min_delta=0.0001, cooldown=0, min_lr=1e-7)\n",
        "    callbacks = [checkpoint, earlystop, reduce_lr]\n",
        "\n",
        "    # Train the model\n",
        "    history = attention_model.fit(x_train, steps_per_epoch=x_train.samples // 32, epochs=10, validation_data=x_test, validation_steps=x_test.samples // 32, callbacks=callbacks)\n",
        "\n",
        "    # Evaluate the model\n",
        "    result_train = attention_model.evaluate(x_train)\n",
        "    result_test = attention_model.evaluate(x_test)\n",
        "    train_loss, train_accu, train_auc = result_train\n",
        "    test_loss, test_accu, test_auc = result_test\n",
        "\n",
        "    # Store results\n",
        "    all_train_accu.append(train_accu)\n",
        "    all_val_accu.append(test_accu)\n",
        "    all_train_loss.append(train_loss)\n",
        "    all_val_loss.append(test_loss)\n",
        "    all_train_auc.append(train_auc)\n",
        "    all_val_auc.append(test_auc)\n",
        "\n",
        "    all_history['categorical_accuracy'].append(history.history['categorical_accuracy'])\n",
        "    all_history['val_categorical_accuracy'].append(history.history['val_categorical_accuracy'])\n",
        "    all_history['loss'].append(history.history['loss'])\n",
        "    all_history['val_loss'].append(history.history['val_loss'])\n",
        "    all_history['auc'].append(history.history['auc'])\n",
        "    all_history['val_auc'].append(history.history['val_auc'])\n",
        "\n",
        "    # Generate predictions and compute confusion matrix\n",
        "    y_pred_train = attention_model.predict(x_train)\n",
        "    y_pred_train = np.argmax(y_pred_train, axis=1)\n",
        "    y_true_train = x_train.classes\n",
        "    cm_train = confusion_matrix(y_true_train, y_pred_train)\n",
        "    cumulative_cm += cm_train\n",
        "\n",
        "    print(f\"Final training accuracy for fold {fold_index + 1} = {train_accu * 100:.2f}%, validation accuracy = {test_accu * 100:.2f}%\")\n",
        "    print(f\"Final training loss = {train_loss:.2f}, validation loss = {test_loss:.2f}\")\n",
        "    print(f\"Final training AUC = {train_auc:.2f}, validation AUC = {test_auc:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T03:24:53.938792Z",
          "iopub.execute_input": "2024-09-03T03:24:53.939618Z",
          "iopub.status.idle": "2024-09-03T14:53:53.785047Z",
          "shell.execute_reply.started": "2024-09-03T03:24:53.939563Z",
          "shell.execute_reply": "2024-09-03T14:53:53.783886Z"
        },
        "trusted": true,
        "id": "s8RZOAX1C7Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean and standard deviation for all metrics\n",
        "mean_train_accu = np.mean(all_train_accu)\n",
        "mean_val_accu = np.mean(all_val_accu)\n",
        "mean_train_loss = np.mean(all_train_loss)\n",
        "mean_val_loss = np.mean(all_val_loss)\n",
        "mean_train_auc = np.mean(all_train_auc)\n",
        "mean_val_auc = np.mean(all_val_auc)\n",
        "\n",
        "std_train_accu = np.std(all_train_accu)\n",
        "std_val_accu = np.std(all_val_accu)\n",
        "std_train_loss = np.std(all_train_loss)\n",
        "std_val_loss = np.std(all_val_loss)\n",
        "std_train_auc = np.std(all_train_auc)\n",
        "std_val_auc = np.std(all_val_auc)\n",
        "\n"
      ],
      "metadata": {
        "id": "-4OAVQolDlMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print overall results\n",
        "print(\"\\nOverall Results:\")\n",
        "print(f\"Mean training accuracy = {mean_train_accu * 100:.2f}% ± {std_train_accu * 100:.2f}%\")\n",
        "print(f\"Mean validation accuracy = {mean_val_accu * 100:.2f}% ± {std_val_accu * 100:.2f}%\")\n",
        "print(f\"Mean training loss = {mean_train_loss:.2f} ± {std_train_loss:.2f}\")\n",
        "print(f\"Mean validation loss = {mean_val_loss:.2f} ± {std_val_loss:.2f}\")\n",
        "print(f\"Mean training AUC = {mean_train_auc:.2f} ± {std_train_auc:.2f}\")\n",
        "print(f\"Mean validation AUC = {mean_val_auc:.2f} ± {std_val_auc:.2f}\")\n"
      ],
      "metadata": {
        "id": "mA-7JsTvDn9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize mean results over all folds\n",
        "mean_history = {key: np.mean(np.array(all_history[key]), axis=0) for key in all_history.keys()}\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(mean_history['categorical_accuracy'], label='Train Accuracy')\n",
        "plt.plot(mean_history['val_categorical_accuracy'], label='Test Accuracy')\n",
        "plt.title('Average Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(mean_history['loss'], label='Train Loss')\n",
        "plt.plot(mean_history['val_loss'], label='Test Loss')\n",
        "plt.title('Average Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(mean_history['auc'], label='Train AUC')\n",
        "plt.plot(mean_history['val_auc'], label='Test AUC')\n",
        "plt.title('Average Model AUC')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('AUC')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V2ei_pWADq-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.colors import LinearSegmentedColormap  # Add this import\n",
        "# Compute and visualize the average confusion matrix\n",
        "average_cm = cumulative_cm / n_splits\n",
        "target_names = list(x_train.class_indices.keys())\n",
        "\n",
        "colors = [(0.8, 1, 0.8), (0.7, 0.9, 1)]\n",
        "cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(average_cm, interpolation='nearest', cmap=cmap)\n",
        "plt.title('Average Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(target_names))\n",
        "plt.xticks(tick_marks, target_names, rotation=90)\n",
        "plt.yticks(tick_marks, target_names)\n",
        "\n",
        "for i, j in itertools.product(range(average_cm.shape[0]), range(average_cm.shape[1])):\n",
        "    plt.text(j, i, format(average_cm[i, j], '.2f'), horizontalalignment=\"center\", color=\"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "# Completion message\n",
        "print(\"All folds completed.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T15:00:51.484413Z",
          "iopub.execute_input": "2024-09-03T15:00:51.485128Z",
          "iopub.status.idle": "2024-09-03T15:00:51.844651Z",
          "shell.execute_reply.started": "2024-09-03T15:00:51.485085Z",
          "shell.execute_reply": "2024-09-03T15:00:51.843920Z"
        },
        "trusted": true,
        "id": "H5Zt_M-gC7Q_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}